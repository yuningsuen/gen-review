import { NextRequest, NextResponse } from "next/server";
import {
  GoogleGenerativeAI,
  HarmCategory,
  HarmBlockThreshold,
} from "@google/generative-ai";
import {
  GeminiReviewGenerator,
  AIReviewRequest,
} from "@/services/geminiReviewGenerator";

export async function POST(request: NextRequest) {
  try {
    const requestData: AIReviewRequest = await request.json();

    // éªŒè¯è¯·æ±‚æ•°æ®
    if (!requestData.platform) {
      return NextResponse.json(
        { success: false, error: "Platform is required" },
        { status: 400 }
      );
    }

    // æ£€æŸ¥Gemini APIå¯†é’¥
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      return NextResponse.json(
        { success: false, error: "Gemini API key not configured" },
        { status: 500 }
      );
    }

    // æ„å»ºæç¤ºè¯
    const prompt = GeminiReviewGenerator.buildPrompt(requestData);

    console.log(
      "Generating review with prompt:",
      prompt.substring(0, 200) + "..."
    );

    // åˆå§‹åŒ– Google Generative AI
    const genAI = new GoogleGenerativeAI(apiKey);

    let modelUsed = "unknown";

    // å®‰å…¨è®¾ç½®
    const safetySettings = [
      {
        category: HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
      {
        category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
      {
        category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
      {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
    ];

    // ç”Ÿæˆé…ç½®
    const generationConfig = {
      temperature: 0.8,
      topK: 40,
      topP: 0.95,
      maxOutputTokens: 1024,
      thinkingConfig: {
        thinkingBudget: 0, // Disables thinking
      },
    };

    // æ¨¡å‹ä¼˜å…ˆçº§åˆ—è¡¨ï¼š2.5 Flash -> 1.5 Pro -> 1.5 Flash
    const modelNames = [
      // "gemini-2.5-pro",
      "gemini-2.5-flash",
      "gemini-1.5-pro",
      "gemini-1.5-flash",
    ];

    for (const modelName of modelNames) {
      try {
        console.log(`ğŸ”„ Trying ${modelName}...`);

        const model = genAI.getGenerativeModel({
          model: modelName,
          generationConfig,
          safetySettings,
        });

        const result = await model.generateContent(prompt);
        const response = result.response;
        const generatedText = response.text();

        if (generatedText && generatedText.trim()) {
          modelUsed = modelName;
          console.log(`âœ… ${modelName} succeeded`);

          // æ¸…ç†ç”Ÿæˆçš„æ–‡æœ¬
          const cleanedText = generatedText
            .trim()
            .replace(/^["']|["']$/g, "") // ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„å¼•å·
            .replace(/\n\s*\n/g, "\n") // åˆå¹¶å¤šä¸ªç©ºè¡Œ
            .trim();

          const tokensUsed = response.usageMetadata?.totalTokenCount || 0;
          const promptTokens = response.usageMetadata?.promptTokenCount || 0;
          const candidatesTokens =
            response.usageMetadata?.candidatesTokenCount || 0;

          console.log(
            `ğŸ“Š Token usage - Total: ${tokensUsed}, Prompt: ${promptTokens}, Response: ${candidatesTokens}`
          );

          return NextResponse.json({
            success: true,
            generatedReview: cleanedText,
            metadata: {
              platform: requestData.platform,
              originalReviewsCount: requestData.existingReviews.length,
              generatedLength: cleanedText.length,
              modelUsed: modelUsed,
              tokensUsed: tokensUsed,
              promptTokens: promptTokens,
              responseTokens: candidatesTokens,
              timestamp: new Date().toISOString(),
            },
          });
        } else {
          console.log(`âš ï¸ ${modelName} returned empty response`);
        }
      } catch (error) {
        console.log(
          `âŒ ${modelName} failed:`,
          error instanceof Error ? error.message : error
        );
        // ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        continue;
      }
    }

    // å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
    console.error("ğŸš« All Gemini models failed");
    return NextResponse.json(
      {
        success: false,
        error: "All Gemini models failed to generate content",
        details: `Tried models: ${modelNames.join(", ")}`,
        modelsAttempted: modelNames,
      },
      { status: 500 }
    );
  } catch (error) {
    console.error("ğŸ’¥ Error in AI review generation:", error);
    return NextResponse.json(
      {
        success: false,
        error: "Internal server error",
        details: error instanceof Error ? error.message : "Unknown error",
      },
      { status: 500 }
    );
  }
}
